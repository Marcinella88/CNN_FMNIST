{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979d0ea6",
   "metadata": {},
   "source": [
    "**Import bibliotek:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec777fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0327d",
   "metadata": {},
   "source": [
    "**Podział danych na zbiór treningowy, walidacyjny oraz testowy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313d38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_ld, y_train_ld), (x_test_ld, y_test_ld) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "images = np.concatenate([x_train_ld, x_test_ld], axis=0) # zbiór zawierający wszystkie zdjęcia\n",
    "labels = np.concatenate([y_train_ld, y_test_ld], axis=0) # zbiór zawierający wszystkie etykiety\n",
    "\n",
    "X_train_tt, X_test, y_train_tt, y_test = \\\n",
    "    train_test_split(images, labels, test_size=0.1, random_state=10, stratify=labels) #Podział na zbiór treningowy oraz testowy\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X_train_tt, y_train_tt, test_size=0.1, random_state=10, stratify=y_train_tt) #Wydzielenie zbiór treningowy oraz walidacyjnego z części treningowej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e7095",
   "metadata": {},
   "source": [
    "**Tworzenie Datasetów TF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae4153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE              # \n",
    "BATCH = 128                               # Zadeklarowanie wartości batch - porcja danych\n",
    "        \n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0   # normalizacja wartości pikseli z zakresu 0-255 na 0-1.\n",
    "    x = tf.expand_dims(x, -1)            # dodanie trzeciego wymiaru na tablicy\n",
    "    return x, y\n",
    "\n",
    "train_ds = (tf.data.Dataset.from_tensor_slices((X_train, y_train))           # tworzenie obiektu Dataset dla TF (obraz,etykieta)\n",
    "            .shuffle(len(X_train), seed=42, reshuffle_each_iteration=True)   # tasuje dane (tasowanie w pełnym zakresie, losowość powtarzalna, dane będą tasowane przy kazdym przejściu przez epokę)\n",
    "            .map(preprocess, num_parallel_calls=AUTOTUNE)                    # przetwarzanie danych (funkcja preprocess, zmiana wymiarów)\n",
    "            .batch(BATCH).prefetch(AUTOTUNE))                                # grupuje dane na paczki po BATCH-elementów, przygotowuje kolejną porcję danych z wyprzedzeniem. \n",
    "\n",
    "val_ds = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "          .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "          .batch(BATCH).prefetch(AUTOTUNE))\n",
    "\n",
    "test_ds = (tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "           .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "           .batch(BATCH).prefetch(AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f1409",
   "metadata": {},
   "source": [
    "**Tworzenie Sieci CNN oraz kompilacja:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4a0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mnist_model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(10, activation='softmax')])\n",
    "\n",
    "f_mnist_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adamW',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94bbc5",
   "metadata": {},
   "source": [
    "**Deklarowanie callbacków:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d979de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=4,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1)\n",
    "\n",
    "ckpt = ModelCheckpoint(\n",
    "    'best_model.keras', \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74167d63",
   "metadata": {},
   "source": [
    "**Trenowanie CNN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154d89a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5248 - loss: 1.2749\n",
      "Epoch 1: val_loss improved from inf to 0.88096, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 80ms/step - accuracy: 0.5250 - loss: 1.2741 - val_accuracy: 0.7686 - val_loss: 0.8810 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7797 - loss: 0.6015\n",
      "Epoch 2: val_loss improved from 0.88096 to 0.46686, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.7798 - loss: 0.6015 - val_accuracy: 0.8321 - val_loss: 0.4669 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8235 - loss: 0.4952\n",
      "Epoch 3: val_loss improved from 0.46686 to 0.41360, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 122ms/step - accuracy: 0.8235 - loss: 0.4951 - val_accuracy: 0.8457 - val_loss: 0.4136 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.8453 - loss: 0.4365\n",
      "Epoch 4: val_loss improved from 0.41360 to 0.38987, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 125ms/step - accuracy: 0.8453 - loss: 0.4365 - val_accuracy: 0.8492 - val_loss: 0.3899 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.8556 - loss: 0.4010\n",
      "Epoch 5: val_loss improved from 0.38987 to 0.33164, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 121ms/step - accuracy: 0.8556 - loss: 0.4010 - val_accuracy: 0.8757 - val_loss: 0.3316 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8697 - loss: 0.3646\n",
      "Epoch 6: val_loss improved from 0.33164 to 0.32003, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.8697 - loss: 0.3646 - val_accuracy: 0.8854 - val_loss: 0.3200 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8745 - loss: 0.3435\n",
      "Epoch 7: val_loss improved from 0.32003 to 0.29412, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 89ms/step - accuracy: 0.8745 - loss: 0.3435 - val_accuracy: 0.8905 - val_loss: 0.2941 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8847 - loss: 0.3182\n",
      "Epoch 8: val_loss improved from 0.29412 to 0.28237, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 120ms/step - accuracy: 0.8847 - loss: 0.3182 - val_accuracy: 0.8940 - val_loss: 0.2824 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.8844 - loss: 0.3200\n",
      "Epoch 9: val_loss did not improve from 0.28237\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 143ms/step - accuracy: 0.8844 - loss: 0.3200 - val_accuracy: 0.8908 - val_loss: 0.2985 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.8936 - loss: 0.2976\n",
      "Epoch 10: val_loss improved from 0.28237 to 0.27578, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 137ms/step - accuracy: 0.8936 - loss: 0.2976 - val_accuracy: 0.8952 - val_loss: 0.2758 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.8939 - loss: 0.2947\n",
      "Epoch 11: val_loss improved from 0.27578 to 0.25982, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 143ms/step - accuracy: 0.8939 - loss: 0.2947 - val_accuracy: 0.9048 - val_loss: 0.2598 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.8983 - loss: 0.2806\n",
      "Epoch 12: val_loss improved from 0.25982 to 0.25446, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 142ms/step - accuracy: 0.8983 - loss: 0.2806 - val_accuracy: 0.9054 - val_loss: 0.2545 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.9013 - loss: 0.2738\n",
      "Epoch 13: val_loss improved from 0.25446 to 0.24886, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 146ms/step - accuracy: 0.9013 - loss: 0.2738 - val_accuracy: 0.9071 - val_loss: 0.2489 - learning_rate: 0.0010\n",
      "Epoch 14/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.9047 - loss: 0.2651\n",
      "Epoch 14: val_loss improved from 0.24886 to 0.24323, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 138ms/step - accuracy: 0.9047 - loss: 0.2651 - val_accuracy: 0.9094 - val_loss: 0.2432 - learning_rate: 0.0010\n",
      "Epoch 15/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9046 - loss: 0.2601\n",
      "Epoch 15: val_loss improved from 0.24323 to 0.24248, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 100ms/step - accuracy: 0.9046 - loss: 0.2601 - val_accuracy: 0.9073 - val_loss: 0.2425 - learning_rate: 0.0010\n",
      "Epoch 16/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9083 - loss: 0.2537\n",
      "Epoch 16: val_loss improved from 0.24248 to 0.23926, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 124ms/step - accuracy: 0.9083 - loss: 0.2537 - val_accuracy: 0.9117 - val_loss: 0.2393 - learning_rate: 0.0010\n",
      "Epoch 17/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9085 - loss: 0.2544\n",
      "Epoch 17: val_loss did not improve from 0.23926\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 124ms/step - accuracy: 0.9085 - loss: 0.2544 - val_accuracy: 0.9075 - val_loss: 0.2400 - learning_rate: 0.0010\n",
      "Epoch 18/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9129 - loss: 0.2403\n",
      "Epoch 18: val_loss improved from 0.23926 to 0.22560, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 126ms/step - accuracy: 0.9129 - loss: 0.2403 - val_accuracy: 0.9133 - val_loss: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 19/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9149 - loss: 0.2380\n",
      "Epoch 19: val_loss did not improve from 0.22560\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 125ms/step - accuracy: 0.9149 - loss: 0.2380 - val_accuracy: 0.8990 - val_loss: 0.2702 - learning_rate: 0.0010\n",
      "Epoch 20/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9159 - loss: 0.2386\n",
      "Epoch 20: val_loss improved from 0.22560 to 0.22134, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 126ms/step - accuracy: 0.9159 - loss: 0.2386 - val_accuracy: 0.9149 - val_loss: 0.2213 - learning_rate: 0.0010\n",
      "Epoch 21/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.9153 - loss: 0.2335\n",
      "Epoch 21: val_loss improved from 0.22134 to 0.21303, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 125ms/step - accuracy: 0.9153 - loss: 0.2335 - val_accuracy: 0.9210 - val_loss: 0.2130 - learning_rate: 0.0010\n",
      "Epoch 22/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.9202 - loss: 0.2196\n",
      "Epoch 22: val_loss did not improve from 0.21303\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 124ms/step - accuracy: 0.9202 - loss: 0.2197 - val_accuracy: 0.9102 - val_loss: 0.2407 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9201 - loss: 0.2222\n",
      "Epoch 23: val_loss did not improve from 0.21303\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 123ms/step - accuracy: 0.9201 - loss: 0.2222 - val_accuracy: 0.9065 - val_loss: 0.2463 - learning_rate: 0.0010\n",
      "Epoch 24/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9188 - loss: 0.2179\n",
      "Epoch 24: val_loss improved from 0.21303 to 0.21032, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 122ms/step - accuracy: 0.9188 - loss: 0.2179 - val_accuracy: 0.9203 - val_loss: 0.2103 - learning_rate: 0.0010\n",
      "Epoch 25/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9221 - loss: 0.2109\n",
      "Epoch 25: val_loss did not improve from 0.21032\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 123ms/step - accuracy: 0.9221 - loss: 0.2109 - val_accuracy: 0.9203 - val_loss: 0.2122 - learning_rate: 0.0010\n",
      "Epoch 26/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9227 - loss: 0.2107\n",
      "Epoch 26: val_loss improved from 0.21032 to 0.20622, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 128ms/step - accuracy: 0.9227 - loss: 0.2107 - val_accuracy: 0.9213 - val_loss: 0.2062 - learning_rate: 0.0010\n",
      "Epoch 27/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9236 - loss: 0.2123\n",
      "Epoch 27: val_loss did not improve from 0.20622\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 123ms/step - accuracy: 0.9236 - loss: 0.2123 - val_accuracy: 0.9219 - val_loss: 0.2106 - learning_rate: 0.0010\n",
      "Epoch 28/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9233 - loss: 0.2098\n",
      "Epoch 28: val_loss improved from 0.20622 to 0.19972, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 120ms/step - accuracy: 0.9233 - loss: 0.2098 - val_accuracy: 0.9237 - val_loss: 0.1997 - learning_rate: 0.0010\n",
      "Epoch 29/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9272 - loss: 0.1971\n",
      "Epoch 29: val_loss did not improve from 0.19972\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 119ms/step - accuracy: 0.9272 - loss: 0.1971 - val_accuracy: 0.9230 - val_loss: 0.2053 - learning_rate: 0.0010\n",
      "Epoch 30/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9278 - loss: 0.1981\n",
      "Epoch 30: val_loss did not improve from 0.19972\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 106ms/step - accuracy: 0.9278 - loss: 0.1981 - val_accuracy: 0.9241 - val_loss: 0.2029 - learning_rate: 0.0010\n",
      "Epoch 31/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9282 - loss: 0.1924\n",
      "Epoch 31: val_loss improved from 0.19972 to 0.19664, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 102ms/step - accuracy: 0.9282 - loss: 0.1924 - val_accuracy: 0.9263 - val_loss: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 32/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9300 - loss: 0.1913\n",
      "Epoch 32: val_loss did not improve from 0.19664\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 121ms/step - accuracy: 0.9300 - loss: 0.1914 - val_accuracy: 0.9219 - val_loss: 0.1992 - learning_rate: 0.0010\n",
      "Epoch 33/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9339 - loss: 0.1850\n",
      "Epoch 33: val_loss did not improve from 0.19664\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 128ms/step - accuracy: 0.9339 - loss: 0.1850 - val_accuracy: 0.9238 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 34/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9313 - loss: 0.1868\n",
      "Epoch 34: val_loss did not improve from 0.19664\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 122ms/step - accuracy: 0.9313 - loss: 0.1868 - val_accuracy: 0.9232 - val_loss: 0.2086 - learning_rate: 0.0010\n",
      "Epoch 35/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9312 - loss: 0.1836\n",
      "Epoch 35: val_loss improved from 0.19664 to 0.19170, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 128ms/step - accuracy: 0.9312 - loss: 0.1836 - val_accuracy: 0.9294 - val_loss: 0.1917 - learning_rate: 0.0010\n",
      "Epoch 36/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9339 - loss: 0.1788\n",
      "Epoch 36: val_loss did not improve from 0.19170\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 124ms/step - accuracy: 0.9339 - loss: 0.1788 - val_accuracy: 0.9263 - val_loss: 0.1928 - learning_rate: 0.0010\n",
      "Epoch 37/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9337 - loss: 0.1812\n",
      "Epoch 37: val_loss did not improve from 0.19170\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.9337 - loss: 0.1812 - val_accuracy: 0.9211 - val_loss: 0.2147 - learning_rate: 0.0010\n",
      "Epoch 38/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9355 - loss: 0.1786\n",
      "Epoch 38: val_loss did not improve from 0.19170\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 122ms/step - accuracy: 0.9355 - loss: 0.1786 - val_accuracy: 0.9260 - val_loss: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 39/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9367 - loss: 0.1727\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.19170\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.9367 - loss: 0.1727 - val_accuracy: 0.9270 - val_loss: 0.1982 - learning_rate: 0.0010\n",
      "Epoch 40/40\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9407 - loss: 0.1543\n",
      "Epoch 40: val_loss improved from 0.19170 to 0.18050, saving model to best_model.keras\n",
      "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 121ms/step - accuracy: 0.9407 - loss: 0.1543 - val_accuracy: 0.9332 - val_loss: 0.1805 - learning_rate: 2.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 40.\n"
     ]
    }
   ],
   "source": [
    "history = f_mnist_model.fit(\n",
    "    train_ds,\n",
    "    validation_data= val_ds,\n",
    "    epochs=40,\n",
    "    callbacks=[reduce_lr, early_stop, ckpt],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d11778",
   "metadata": {},
   "source": [
    "**Weryfikacja metryk na zbiorze testowym:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d8f870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9357 - loss: 0.1673\n",
      "Test loss: 0.1661 | Test acc: 0.9391\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = f_mnist_model.evaluate(test_ds, verbose=1)\n",
    "print(f\"Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9fb92",
   "metadata": {},
   "source": [
    "**Podsumowanie modelu CNN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31aac694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385,056</span> (1.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m385,056\u001b[0m (1.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,330</span> (501.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,330\u001b[0m (501.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256,662</span> (1002.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m256,662\u001b[0m (1002.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73748d8",
   "metadata": {},
   "source": [
    "**Sprawdź czy istniee folder:\"export\", jeśli nie to to stwórz:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9c2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"export\", exist_ok=True)\n",
    "f_mnist_model.save(\"export/fashion_cnn_savedmodel.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9c8c5",
   "metadata": {},
   "source": [
    "**Export modelu do folderu:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c5e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mnist_model.save(\"export/fashion_cnn_savedmodel.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e3476",
   "metadata": {},
   "source": [
    "**Import modelu:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53478861",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imported = tf.keras.models.load_model(\"export/fashion_cnn_savedmodel.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fd2dd",
   "metadata": {},
   "source": [
    "**Tworzenie funkcji/interfejsu która przedstawi nam wskazany obraz, etykietę oraz predykcję modelu:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea7ed263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(model, X_test, y_test, idx):\n",
    "    \n",
    "    product_names = [\n",
    "        \"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "        \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "    \n",
    "   \n",
    "    x = np.expand_dims(np.expand_dims(X_test[idx].astype(\"float32\") / 255.0, -1), 0)\n",
    "\n",
    "    probs = model.predict(x, verbose=0)\n",
    "    y_pred = np.argmax(probs, axis=1)[0]\n",
    "    conf = probs[0, y_pred]\n",
    "\n",
    "    true_name = product_names[int(y_test[idx])]\n",
    "    pred_name = product_names[y_pred]\n",
    "\n",
    "    plt.imshow(X_test[idx], cmap=\"gray\")\n",
    "    plt.title(f\"Etykieta: {true_name}\\nPredykcja: {pred_name} ({conf:.2f})\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b152c3",
   "metadata": {},
   "source": [
    "**Wpisz wartość dla \"nr_foto\" aby poniżej ruchamiając funkcję wyświetlić obrazek, etykietę oraz predykcję:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ef5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_foto = 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7ad381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prediction(model_imported,X_test, y_test,nr_foto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
